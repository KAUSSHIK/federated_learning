{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedLib: Heterogeneous Federated Learning using Dynamic Model Pruning and Adaptive Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing supportive libaries\n",
    "This notebook shows a demo on PyTorch back-end model impelementation.\n",
    "\n",
    "In the very begining, we import the supporting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from fedlib.ve import FEDDFEnv as Simulator\n",
    "from fedlib.lib import Server, Client\n",
    "from fedlib.networks import resnet20\n",
    "from fedlib.lib.sampler import random_sampler\n",
    "from fedlib.lib.algo import feddp\n",
    "from fedlib.datasets import partition_data, get_dataloader,get_client_dataloader\n",
    "from fedlib.utils import get_logger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define arguments\n",
    "Here we define arguments. To show an intuitive example, we show the demo store all the parameters in a dictionary in the following code block.\n",
    "We also provide APIs for you create your arguments in a `*.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "args[\"n_clients\"] = 2\n",
    "args[\"device\"] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args['sample_fn'] = random_sampler\n",
    "args['trainer'] = feddp(logger=get_logger())\n",
    "args['communicator'] = None\n",
    "args[\"test_dataset\"] = None\n",
    "args[\"partition\"] = \"noniid-labeldir\"\n",
    "args[\"dataset\"] = \"cifar10\"\n",
    "args[\"datadir\"] = \"./data\"\n",
    "args[\"beta\"] = 0.5\n",
    "args[\"batch_size\"] = 64\n",
    "args[\"global_model\"] = resnet20()\n",
    "args[\"lr\"] = 0.01\n",
    "args[\"optimizer\"] = \"SGD\"\n",
    "args[\"lr_scheduler\"] = \"ExponentialLR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataset for server, and passing it as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data statistics: {0: {0: 1016, 1: 1431, 2: 4538, 3: 3328, 4: 1677, 5: 2289, 6: 3536, 7: 1113, 8: 4970, 9: 4629}, 1: {0: 3984, 1: 3569, 2: 462, 3: 1672, 4: 3323, 5: 2711, 6: 1464, 7: 3887, 8: 30, 9: 371}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts = partition_data(\n",
    "    args[\"dataset\"], args[\"datadir\"], args['partition'], args['n_clients'], beta=args['beta'])\n",
    "n_classes = len(np.unique(y_train))\n",
    "train_dl_global, test_dl_global, train_ds_global, test_ds_global = get_dataloader(args[\"dataset\"],\n",
    "                                                                                    args[\"datadir\"],\n",
    "                                                                                      args[\"batch_size\"],\n",
    "                                                                                      32)\n",
    "args[\"test_dataset\"] = test_dl_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create server and clients objects\n",
    "Here we use the arguments we defined before, and create server and clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "key: 0 \t, dataid 28527 train_ds: 22821 test_ds: 5706\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "key: 1 \t, dataid 21473 train_ds: 17178 test_ds: 4295\n",
      "Total train: 39999 \t Total test: 10001\n"
     ]
    }
   ],
   "source": [
    "server = Server(**args)\n",
    "clients = {}\n",
    "\n",
    "data_loaders, test_loaders = get_client_dataloader(args[\"dataset\"], args[\"datadir\"], args['batch_size'], 32, net_dataidx_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client: 0 \tTrain: 22821 \tTest: 5706\n",
      "Client: 1 \tTrain: 17178 \tTest: 4295\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for id in range(args[\"n_clients\"]):\n",
    "    # dataidxs = net_dataidx_map[id]\n",
    "    args[\"id\"] = id\n",
    "    # args[\"trainloader\"], _, _, _ = get_dataloader(args[\"dataset\"], args[\"datadir\"], args['batch_size'], 32, dataidxs)\n",
    "    args[\"trainloader\"] = data_loaders[id]\n",
    "    args[\"testloader\"] =test_loaders[id]\n",
    "    args[\"model\"] = copy.deepcopy(args[\"global_model\"])\n",
    "    args['criterion'] = torch.nn.CrossEntropyLoss()\n",
    "    clients[id] = Client(**args)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simulator\n",
    "\n",
    "Simulator simulates the virtual federated learning environments, and run server and clients on single device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(server=server, clients=clients, communication_rounds=10,n_clients= 2,sample_rate=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulator\n",
    "User API Simulator.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:*******starting rounds 1 optimization******\n",
      "INFO:root:optimize the 1-th clients\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sixingyu/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:138: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "INFO:root:Layer: conv1, Sparsity: 0.23%\n",
      "INFO:root:Layer: layer1.0.conv1, Sparsity: 0.56%\n",
      "INFO:root:Layer: layer1.0.conv2, Sparsity: 0.65%\n",
      "INFO:root:Layer: layer1.1.conv1, Sparsity: 0.52%\n",
      "INFO:root:Layer: layer1.1.conv2, Sparsity: 0.65%\n",
      "INFO:root:Layer: layer1.2.conv1, Sparsity: 0.56%\n",
      "INFO:root:Layer: layer1.2.conv2, Sparsity: 0.61%\n",
      "INFO:root:Layer: layer2.0.conv1, Sparsity: 0.52%\n",
      "INFO:root:Layer: layer2.0.conv2, Sparsity: 0.82%\n",
      "INFO:root:Layer: layer2.1.conv1, Sparsity: 1.04%\n",
      "INFO:root:Layer: layer2.1.conv2, Sparsity: 1.01%\n",
      "INFO:root:Layer: layer2.2.conv1, Sparsity: 1.09%\n",
      "INFO:root:Layer: layer2.2.conv2, Sparsity: 0.89%\n",
      "INFO:root:Layer: layer3.0.conv1, Sparsity: 0.88%\n",
      "INFO:root:Layer: layer3.0.conv2, Sparsity: 1.39%\n",
      "INFO:root:Layer: layer3.1.conv1, Sparsity: 1.36%\n",
      "INFO:root:Layer: layer3.1.conv2, Sparsity: 1.39%\n",
      "INFO:root:Layer: layer3.2.conv1, Sparsity: 1.29%\n",
      "INFO:root:Layer: layer3.2.conv2, Sparsity: 1.38%\n",
      "INFO:root:Model sparsity: 0.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv1, Sparsity: 0.23%\n",
      "Layer: layer1.0.conv1, Sparsity: 0.56%\n",
      "Layer: layer1.0.conv2, Sparsity: 0.65%\n",
      "Layer: layer1.1.conv1, Sparsity: 0.52%\n",
      "Layer: layer1.1.conv2, Sparsity: 0.65%\n",
      "Layer: layer1.2.conv1, Sparsity: 0.56%\n",
      "Layer: layer1.2.conv2, Sparsity: 0.61%\n",
      "Layer: layer2.0.conv1, Sparsity: 0.52%\n",
      "Layer: layer2.0.conv2, Sparsity: 0.82%\n",
      "Layer: layer2.1.conv1, Sparsity: 1.04%\n",
      "Layer: layer2.1.conv2, Sparsity: 1.01%\n",
      "Layer: layer2.2.conv1, Sparsity: 1.09%\n",
      "Layer: layer2.2.conv2, Sparsity: 0.89%\n",
      "Layer: layer3.0.conv1, Sparsity: 0.88%\n",
      "Layer: layer3.0.conv2, Sparsity: 1.39%\n",
      "Layer: layer3.1.conv1, Sparsity: 1.36%\n",
      "Layer: layer3.1.conv2, Sparsity: 1.39%\n",
      "Layer: layer3.2.conv1, Sparsity: 1.29%\n",
      "Layer: layer3.2.conv2, Sparsity: 1.38%\n",
      "Model sparsity: 0.89%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 2 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m simulator\u001b[39m.\u001b[39;49mrun(local_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m,pruning_threshold\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/fedlib/ve/feddf.py:46\u001b[0m, in \u001b[0;36mFEDDFEnv.run\u001b[0;34m(self, local_epochs, pruning_threshold)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mid not match\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m client\u001b[39m.\u001b[39mset_model_params(global_model_param)\n\u001b[0;32m---> 46\u001b[0m client\u001b[39m.\u001b[39;49mclient_update( epochs\u001b[39m=\u001b[39;49mlocal_epochs,pruning_threshold\u001b[39m=\u001b[39;49mpruning_threshold)\n\u001b[1;32m     48\u001b[0m nets_params\u001b[39m.\u001b[39mappend(client\u001b[39m.\u001b[39mget_model_params())\n\u001b[1;32m     49\u001b[0m local_datasize\u001b[39m.\u001b[39mappend(client\u001b[39m.\u001b[39mdatasize)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/fedlib/lib/client.py:72\u001b[0m, in \u001b[0;36mClient.client_update\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mscheduler\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\n\u001b[1;32m     70\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcriterion\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion\n\u001b[0;32m---> 72\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trainer\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/fedlib/lib/algo/feddp/feddf.py:65\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, model, dataloader, criterion, optimizer, scheduler, epochs, pruning_threshold, device)\u001b[0m\n\u001b[1;32m     61\u001b[0m epoch_loss\u001b[39m.\u001b[39mappend(\u001b[39msum\u001b[39m(batch_loss) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(batch_loss) \u001b[39mif\u001b[39;00m batch_loss \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m)\n\u001b[1;32m     63\u001b[0m accuracy \u001b[39m=\u001b[39m correct \u001b[39m/\u001b[39m total\n\u001b[0;32m---> 65\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39;49m\u001b[39mEpoch: \u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m\\t\u001b[39;49;00m\u001b[39mLoss: \u001b[39;49m\u001b[39m{:.6f}\u001b[39;49;00m\u001b[39m\\t\u001b[39;49;00m\u001b[39mAccuracy:\u001b[39;49m\u001b[39m{:.6f}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(epoch, \u001b[39msum\u001b[39;49m(epoch_loss) \u001b[39m/\u001b[39;49m \u001b[39mlen\u001b[39;49m(epoch_loss)), accuracy)\n\u001b[1;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mAccuracy:\u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39mModel sparsity: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     68\u001b[0m         epoch, \u001b[39msum\u001b[39m(epoch_loss) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(epoch_loss)), accuracy,model_sparsity\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: Replacement index 2 out of range for positional args tuple"
     ]
    }
   ],
   "source": [
    "simulator.run(local_epochs=2,pruning_threshold=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14599062b2f9b2c02bf607b744cd02923df131fc806bc02ca9049e6dcc66a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
