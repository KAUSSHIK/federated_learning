{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedLib: Simulating FedAvg using FedLib virtual Federated environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing supportive libaries\n",
    "This notebook shows a demo on PyTorch back-end model impelementation.\n",
    "\n",
    "In the very begining, we import the supporting libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import copy\n",
    "from fedlib.utils import get_logger\n",
    "from fedlib.ve.mtfl import MTFLEnv\n",
    "from fedlib.lib import Server, Client\n",
    "from fedlib.networks import resnet20\n",
    "from fedlib.lib.sampler import random_sampler\n",
    "from fedlib.lib.algo.torch.mtfl import Trainer\n",
    "from fedlib.datasets import partition_data, get_dataloader,get_client_dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define arguments\n",
    "Here we define arguments. To show an intuitive example, we show the demo store all the parameters in a dictionary in the following code block.\n",
    "We also provide APIs for you create your arguments in a `*.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "args = {}\n",
    "args[\"n_clients\"] = 10\n",
    "args[\"device\"] = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "args['sample_fn'] = random_sampler\n",
    "args['trainer'] = Trainer(logger)\n",
    "args['communicator'] = None\n",
    "args[\"test_dataset\"] = None\n",
    "args[\"partition\"] = \"noniid-labeldir\"\n",
    "args[\"dataset\"] = \"mnist\"\n",
    "args[\"datadir\"] = \"./data\"\n",
    "args[\"beta\"] = 0.5\n",
    "args[\"batch_size\"] = 64\n",
    "args[\"lr\"] = 0.01\n",
    "args[\"optimizer\"] = \"SGD\"\n",
    "args[\"lr_scheduler\"] = \"ExponentialLR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataset for server, and passing it as an argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data statistics: {0: {0: 1511, 1: 1125, 2: 1939, 3: 159, 4: 1941}, 1: {0: 1378, 1: 1366, 2: 737, 3: 2768}, 2: {0: 267, 1: 378, 2: 2572, 3: 307, 4: 588, 5: 20, 6: 50, 7: 780, 8: 44, 9: 226}, 3: {0: 206, 1: 130, 2: 216, 3: 527, 4: 1110, 5: 1342, 6: 36, 7: 2066, 8: 317, 9: 55}, 4: {0: 176, 1: 759, 2: 107, 3: 48, 4: 89, 5: 726, 6: 770, 7: 496, 8: 1510, 9: 177}, 5: {0: 876, 2: 87, 3: 518, 4: 1295, 5: 52, 6: 12, 7: 737, 8: 2233, 9: 2996}, 6: {0: 233, 1: 688, 2: 39, 3: 549, 4: 158, 5: 318, 6: 593, 7: 680, 8: 365, 9: 1812}, 7: {0: 476, 1: 175, 3: 2, 5: 690, 6: 949, 7: 433, 8: 992, 9: 633}, 8: {0: 405, 1: 279, 2: 253, 3: 63, 4: 248, 5: 1397, 6: 1642, 7: 1073, 8: 389, 9: 50}, 9: {0: 395, 1: 1842, 2: 8, 3: 1190, 4: 413, 5: 876, 6: 1866, 8: 1}}\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test, net_dataidx_map, traindata_cls_counts = partition_data(\n",
    "    args[\"dataset\"], args[\"datadir\"], args['partition'], args['n_clients'], beta=args['beta'])\n",
    "n_classes = len(np.unique(y_train))\n",
    "train_dl_global, test_dl_global, train_ds_global, test_ds_global = get_dataloader(args[\"dataset\"],\n",
    "                                                                                    args[\"datadir\"],\n",
    "                                                                                      args[\"batch_size\"],\n",
    "                                                                                      32)\n",
    "args[\"test_dataset\"] = test_dl_global"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model Arc\n",
    "Model must contains encoder, decoder, predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.predictor = nn.Linear(in_features=32, out_features=10, bias=True)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.predictor(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 28, 28]) torch.Size([10, 1, 28, 28]) torch.Size([10, 10])\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "x = torch.rand([10,1,28,28])\n",
    "representation = model.encoder(x)\n",
    "x_ = model.decoder(representation)\n",
    "pred = model(x)\n",
    "print(x.shape,x_.shape,pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create server and clients objects\n",
    "Here we use the arguments we defined before, and create server and clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "args[\"global_model\"] = model.encoder\n",
    "server = Server(**args)\n",
    "clients = {}\n",
    "\n",
    "data_loaders = get_client_dataloader(args[\"dataset\"], args[\"datadir\"], args['batch_size'], 32, net_dataidx_map)\n",
    "\n",
    "criterion_pred = torch.nn.CrossEntropyLoss()\n",
    "criterion_rep = torch.nn.MSELoss()\n",
    "\n",
    "args[\"criterion\"]={\n",
    "    \"criterion_rep\": criterion_rep,\n",
    "    \"criterion_pred\": criterion_pred\n",
    "    }\n",
    "\n",
    "for id in range(args[\"n_clients\"]):\n",
    "    # dataidxs = net_dataidx_map[id]\n",
    "    args[\"id\"] = id\n",
    "    # args[\"trainloader\"], _, _, _ = get_dataloader(args[\"dataset\"], args[\"datadir\"], args['batch_size'], 32, dataidxs)\n",
    "    args[\"trainloader\"] = data_loaders[id]\n",
    "    args[\"model\"] = copy.deepcopy(model)\n",
    "    clients[id] = Client(**args)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create simulator\n",
    "\n",
    "Simulator simulates the virtual federated learning environments, and run server and clients on single device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = MTFLEnv(server=server, clients=clients, communication_rounds=10,n_clients= 10,sample_rate=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run simulator\n",
    "User API Simulator.run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:*******starting rounds 1 optimization******\n",
      "INFO:root:optimize the 4-th clients\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.458877\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.433209\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.365509\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.318931\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.289380\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.270249\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.171733\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.149680\n",
      "INFO:root:Epoch: 0\tLoss: 2.291434\n",
      "INFO:root:Update Epoch: 1 \tLoss: 2.060631\n",
      "INFO:root:Update Epoch: 1 \tLoss: 2.088791\n",
      "INFO:root:Update Epoch: 1 \tLoss: 2.019820\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.965572\n",
      "INFO:root:Update Epoch: 1 \tLoss: 2.101911\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.849362\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.978142\n",
      "INFO:root:Update Epoch: 1 \tLoss: 2.040374\n",
      "INFO:root:Epoch: 1\tLoss: 2.177208\n",
      "INFO:root:*******starting rounds 2 optimization******\n",
      "INFO:root:optimize the 9-th clients\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.450994\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.417016\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.226083\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.022510\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.934955\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.940995\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.891780\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.758760\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.676401\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.645063\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.635265\n",
      "INFO:root:Epoch: 0\tLoss: 1.950511\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.688900\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.783828\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.545300\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.492899\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.508864\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.429320\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.251340\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.202171\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.410848\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.399988\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.419558\n",
      "INFO:root:Epoch: 1\tLoss: 1.702931\n",
      "INFO:root:*******starting rounds 3 optimization******\n",
      "INFO:root:optimize the 7-th clients\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.533422\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.087558\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.971295\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.806134\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.790350\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.866605\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.827555\n",
      "INFO:root:Epoch: 0\tLoss: 1.886070\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.729044\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.752618\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.671006\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.714985\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.641868\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.565182\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.506176\n",
      "INFO:root:Epoch: 1\tLoss: 1.781099\n",
      "INFO:root:*******starting rounds 4 optimization******\n",
      "INFO:root:optimize the 2-th clients\n",
      "INFO:root:Update Epoch: 0 \tLoss: 4.388025\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.633156\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.371513\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.749988\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.619367\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.799425\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.500324\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.485864\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.260129\n",
      "INFO:root:Epoch: 0\tLoss: 1.653746\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.415854\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.324863\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.557026\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.116260\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.393525\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.348491\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.192700\n",
      "INFO:root:Update Epoch: 1 \tLoss: 0.980658\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.036467\n",
      "INFO:root:Epoch: 1\tLoss: 1.471274\n",
      "INFO:root:*******starting rounds 5 optimization******\n",
      "INFO:root:optimize the 6-th clients\n",
      "INFO:root:Update Epoch: 0 \tLoss: 2.330082\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.840698\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.760976\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.802776\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.771365\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.641486\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.708969\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.480177\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.531934\n",
      "INFO:root:Epoch: 0\tLoss: 1.698393\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.557697\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.340108\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.484307\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.410854\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.355038\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.445450\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.478119\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.426449\n",
      "INFO:root:Update Epoch: 1 \tLoss: 1.642862\n",
      "INFO:root:Epoch: 1\tLoss: 1.557888\n",
      "INFO:root:*******starting rounds 6 optimization******\n",
      "INFO:root:optimize the 6-th clients\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.277417\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.578012\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.052863\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.374658\n",
      "INFO:root:Update Epoch: 0 \tLoss: 1.395160\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m simulator\u001b[39m.\u001b[39;49mrun(local_epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/fedlib/ve/mtfl.py:56\u001b[0m, in \u001b[0;36mMTFLEnv.run\u001b[0;34m(self, local_epochs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mid not match\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m client\u001b[39m.\u001b[39mset_model_params(globa_encoder, module_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m client\u001b[39m.\u001b[39;49mclient_update( epochs\u001b[39m=\u001b[39;49mlocal_epochs)\n\u001b[1;32m     58\u001b[0m nets_encoders\u001b[39m.\u001b[39mappend(client\u001b[39m.\u001b[39mget_model_params(module_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     59\u001b[0m local_datasize\u001b[39m.\u001b[39mappend(client\u001b[39m.\u001b[39mdatasize)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/fedlib/lib/client.py:66\u001b[0m, in \u001b[0;36mClient.client_update\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39moptimizer\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\n\u001b[1;32m     64\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mcriterion\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_trainer\u001b[39m.\u001b[39;49mtrain(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/fedlib/lib/algo/torch/mtfl/mtfl.py:46\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, model, dataloader, criterion, optimizer, epochs, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m loss \u001b[39m=\u001b[39m criterion_pred(pred_out, labels)\n\u001b[1;32m     44\u001b[0m loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m criterion_rep(decodes_out, x)\n\u001b[0;32m---> 46\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     48\u001b[0m \u001b[39m# to avoid nan loss\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39m# torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fedlib/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "simulator.run(local_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedlib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e14599062b2f9b2c02bf607b744cd02923df131fc806bc02ca9049e6dcc66a18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
