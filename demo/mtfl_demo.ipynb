{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(3, 3), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 8, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): ConvTranspose2d(8, 16, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): ConvTranspose2d(16, 8, kernel_size=(5, 5), stride=(3, 3), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): ConvTranspose2d(8, 1, kernel_size=(2, 2), stride=(2, 2), padding=(1, 1))\n",
       "    (5): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = autoencoder()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.random' has no attribute 'randn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/sixingyu/code/fedlib/demo/mtfl_demo.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sixingyu/code/fedlib/demo/mtfl_demo.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mget_submodule(\u001b[39m'\u001b[39m\u001b[39mencoder\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstate_dict()[\u001b[39m'\u001b[39m\u001b[39m0.weight\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msize()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sixingyu/code/fedlib/demo/mtfl_demo.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sixingyu/code/fedlib/demo/mtfl_demo.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m torch\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mrandn([\u001b[39m16\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m3\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.random' has no attribute 'randn'"
     ]
    }
   ],
   "source": [
    "model.get_submodule('encoder').state_dict()['0.weight'].size()\n",
    "import torch\n",
    "torch.rand([16, 1, 3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight',\n",
       "              tensor([[[[ 0.1831,  0.3181,  0.3256],\n",
       "                        [ 0.1740, -0.2782, -0.2167],\n",
       "                        [-0.0123, -0.2232, -0.2152]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1121, -0.3200,  0.0942],\n",
       "                        [ 0.2393, -0.1945,  0.1631],\n",
       "                        [ 0.2360,  0.1167,  0.0892]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0682,  0.1679, -0.1728],\n",
       "                        [ 0.3266,  0.0074,  0.1428],\n",
       "                        [ 0.0519,  0.2610, -0.0363]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2472, -0.2987,  0.3252],\n",
       "                        [ 0.0812,  0.0508, -0.3109],\n",
       "                        [ 0.1820,  0.2317,  0.0745]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1110, -0.1596, -0.0243],\n",
       "                        [-0.1343,  0.1991, -0.3268],\n",
       "                        [-0.2699,  0.1819, -0.1615]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1398, -0.0800,  0.1095],\n",
       "                        [-0.0623,  0.3289,  0.2178],\n",
       "                        [-0.1546, -0.0928, -0.0936]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.1168, -0.0947,  0.3318],\n",
       "                        [-0.2213, -0.1586, -0.2911],\n",
       "                        [ 0.3155, -0.0308, -0.1181]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2761,  0.1680,  0.2971],\n",
       "                        [-0.3089,  0.2130,  0.1768],\n",
       "                        [ 0.1422, -0.2164, -0.1039]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1144, -0.3156,  0.1285],\n",
       "                        [ 0.3285, -0.0160,  0.1741],\n",
       "                        [ 0.0723, -0.1088, -0.1779]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0946, -0.0488, -0.1752],\n",
       "                        [-0.0129,  0.3105,  0.1987],\n",
       "                        [ 0.2286,  0.2626,  0.1398]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0744, -0.2881, -0.2524],\n",
       "                        [-0.2214, -0.0411, -0.3056],\n",
       "                        [-0.2471, -0.0830, -0.1649]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1871, -0.0241,  0.1019],\n",
       "                        [-0.2685, -0.1967, -0.0427],\n",
       "                        [ 0.0149, -0.2574,  0.3050]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2861, -0.2070, -0.2437],\n",
       "                        [-0.2458, -0.0386, -0.0258],\n",
       "                        [-0.0966,  0.2285, -0.1259]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.2981,  0.2580, -0.2527],\n",
       "                        [ 0.1272, -0.1351, -0.0249],\n",
       "                        [-0.1794,  0.2691,  0.0138]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.2316,  0.0005, -0.1888],\n",
       "                        [ 0.0684, -0.3064, -0.0866],\n",
       "                        [-0.0316,  0.2205, -0.1059]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.3079,  0.2021,  0.1947],\n",
       "                        [ 0.1867, -0.0377, -0.3118],\n",
       "                        [ 0.3085, -0.3165,  0.1007]]]])),\n",
       "             ('0.bias',\n",
       "              tensor([-0.0591, -0.0827, -0.0579, -0.1645,  0.0399, -0.2216,  0.1038, -0.1550,\n",
       "                      -0.1565,  0.2241,  0.0393,  0.3289,  0.2997,  0.1565,  0.1440, -0.1510])),\n",
       "             ('3.weight',\n",
       "              tensor([[[[-0.0554,  0.0433,  0.0312],\n",
       "                        [-0.0769,  0.0251, -0.0325],\n",
       "                        [-0.0489,  0.0701,  0.0353]],\n",
       "              \n",
       "                       [[ 0.0772, -0.0419, -0.0807],\n",
       "                        [ 0.0614, -0.0171,  0.0704],\n",
       "                        [ 0.0004,  0.0230,  0.0050]],\n",
       "              \n",
       "                       [[-0.0342,  0.0670,  0.0310],\n",
       "                        [-0.0536,  0.0321, -0.0022],\n",
       "                        [-0.0538, -0.0168,  0.0269]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0754,  0.0584, -0.0313],\n",
       "                        [-0.0761,  0.0285,  0.0485],\n",
       "                        [-0.0822, -0.0271,  0.0248]],\n",
       "              \n",
       "                       [[-0.0315, -0.0453, -0.0550],\n",
       "                        [-0.0346, -0.0637, -0.0171],\n",
       "                        [ 0.0452,  0.0767,  0.0063]],\n",
       "              \n",
       "                       [[-0.0608,  0.0348,  0.0778],\n",
       "                        [-0.0033,  0.0413, -0.0167],\n",
       "                        [-0.0097, -0.0733, -0.0086]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0354, -0.0578,  0.0608],\n",
       "                        [ 0.0142,  0.0755,  0.0106],\n",
       "                        [ 0.0461, -0.0108, -0.0588]],\n",
       "              \n",
       "                       [[ 0.0764,  0.0632, -0.0553],\n",
       "                        [ 0.0329,  0.0635, -0.0491],\n",
       "                        [-0.0677, -0.0256, -0.0123]],\n",
       "              \n",
       "                       [[ 0.0708,  0.0237, -0.0287],\n",
       "                        [-0.0110, -0.0429,  0.0826],\n",
       "                        [-0.0483, -0.0642,  0.0071]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0439,  0.0636, -0.0714],\n",
       "                        [-0.0317, -0.0284,  0.0114],\n",
       "                        [ 0.0793, -0.0254,  0.0719]],\n",
       "              \n",
       "                       [[ 0.0291, -0.0643,  0.0635],\n",
       "                        [ 0.0503,  0.0718, -0.0125],\n",
       "                        [-0.0301, -0.0145, -0.0746]],\n",
       "              \n",
       "                       [[-0.0327,  0.0351,  0.0039],\n",
       "                        [-0.0447,  0.0657, -0.0657],\n",
       "                        [-0.0010, -0.0132,  0.0502]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0718,  0.0290, -0.0586],\n",
       "                        [ 0.0363,  0.0807, -0.0029],\n",
       "                        [-0.0485,  0.0238, -0.0646]],\n",
       "              \n",
       "                       [[ 0.0247, -0.0119, -0.0648],\n",
       "                        [ 0.0068, -0.0174, -0.0089],\n",
       "                        [ 0.0789, -0.0120,  0.0443]],\n",
       "              \n",
       "                       [[ 0.0309,  0.0560, -0.0699],\n",
       "                        [-0.0310, -0.0122,  0.0144],\n",
       "                        [ 0.0416, -0.0188, -0.0471]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0789, -0.0521,  0.0682],\n",
       "                        [ 0.0686,  0.0555,  0.0528],\n",
       "                        [-0.0756, -0.0508,  0.0416]],\n",
       "              \n",
       "                       [[-0.0814, -0.0777, -0.0191],\n",
       "                        [ 0.0304,  0.0680, -0.0772],\n",
       "                        [ 0.0628,  0.0042,  0.0398]],\n",
       "              \n",
       "                       [[-0.0793,  0.0423, -0.0457],\n",
       "                        [-0.0352, -0.0514,  0.0266],\n",
       "                        [ 0.0334, -0.0432, -0.0134]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0021,  0.0375, -0.0202],\n",
       "                        [ 0.0388, -0.0218,  0.0757],\n",
       "                        [-0.0379, -0.0314, -0.0128]],\n",
       "              \n",
       "                       [[ 0.0600,  0.0102,  0.0076],\n",
       "                        [-0.0515, -0.0740,  0.0510],\n",
       "                        [-0.0054, -0.0523,  0.0813]],\n",
       "              \n",
       "                       [[-0.0008,  0.0617,  0.0112],\n",
       "                        [-0.0589, -0.0445,  0.0658],\n",
       "                        [-0.0501,  0.0199, -0.0658]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0056,  0.0354,  0.0798],\n",
       "                        [ 0.0696, -0.0463, -0.0310],\n",
       "                        [-0.0733, -0.0055,  0.0243]],\n",
       "              \n",
       "                       [[ 0.0495, -0.0795,  0.0831],\n",
       "                        [ 0.0689,  0.0600,  0.0016],\n",
       "                        [-0.0135, -0.0369,  0.0496]],\n",
       "              \n",
       "                       [[-0.0475,  0.0486,  0.0740],\n",
       "                        [ 0.0288,  0.0668, -0.0008],\n",
       "                        [ 0.0473, -0.0366,  0.0553]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0419,  0.0563,  0.0707],\n",
       "                        [-0.0195, -0.0421,  0.0068],\n",
       "                        [ 0.0784, -0.0145, -0.0511]],\n",
       "              \n",
       "                       [[ 0.0301,  0.0552,  0.0006],\n",
       "                        [-0.0005,  0.0249,  0.0172],\n",
       "                        [-0.0350,  0.0624,  0.0796]],\n",
       "              \n",
       "                       [[-0.0773,  0.0048,  0.0151],\n",
       "                        [-0.0470, -0.0056,  0.0479],\n",
       "                        [ 0.0330,  0.0517,  0.0386]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0735,  0.0223, -0.0701],\n",
       "                        [-0.0181, -0.0347, -0.0017],\n",
       "                        [ 0.0324,  0.0096,  0.0758]],\n",
       "              \n",
       "                       [[ 0.0356, -0.0230, -0.0352],\n",
       "                        [ 0.0053, -0.0595, -0.0352],\n",
       "                        [-0.0648, -0.0141,  0.0251]],\n",
       "              \n",
       "                       [[ 0.0682,  0.0339,  0.0007],\n",
       "                        [-0.0228, -0.0324, -0.0724],\n",
       "                        [ 0.0804,  0.0610,  0.0476]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0359,  0.0510,  0.0002],\n",
       "                        [-0.0352, -0.0195,  0.0819],\n",
       "                        [ 0.0173, -0.0151,  0.0764]],\n",
       "              \n",
       "                       [[ 0.0733, -0.0714, -0.0313],\n",
       "                        [ 0.0700,  0.0288,  0.0809],\n",
       "                        [ 0.0099,  0.0300, -0.0122]],\n",
       "              \n",
       "                       [[ 0.0231, -0.0025, -0.0559],\n",
       "                        [ 0.0132,  0.0703,  0.0136],\n",
       "                        [-0.0281, -0.0108,  0.0206]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0818,  0.0727, -0.0093],\n",
       "                        [-0.0527, -0.0758,  0.0471],\n",
       "                        [-0.0460, -0.0314,  0.0373]],\n",
       "              \n",
       "                       [[-0.0358, -0.0046, -0.0590],\n",
       "                        [ 0.0259,  0.0049, -0.0587],\n",
       "                        [ 0.0454, -0.0822,  0.0242]],\n",
       "              \n",
       "                       [[ 0.0426, -0.0212, -0.0456],\n",
       "                        [ 0.0372,  0.0308,  0.0195],\n",
       "                        [ 0.0491,  0.0801,  0.0544]]]])),\n",
       "             ('3.bias',\n",
       "              tensor([-0.0659,  0.0336,  0.0447,  0.0077,  0.0400,  0.0801,  0.0322,  0.0687]))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "845a9d0ae98e81ae90bb9e7361181cfa9bffa91900afd9cd03a75c89782c3244"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
